---
title: "D. Using the schedule Clause | Microsoft Docs"
ms.custom: ""
ms.date: "12/03/2016"
ms.prod: "visual-studio-dev14"
ms.reviewer: ""
ms.suite: ""
ms.technology: 
  - "devlang-cpp"
ms.tgt_pltfrm: ""
ms.topic: "article"
dev_langs: 
  - "C++"
ms.assetid: bf3d8f51-ea05-4803-bf55-657c12e91efe
caps.latest.revision: 5
caps.handback.revision: 5
author: "mikeblome"
ms.author: "mblome"
manager: "ghogen"
---
# D. Using the schedule Clause
[!INCLUDE[vs2017banner](../../assembler/inline/includes/vs2017banner.md)]

병렬 영역 적어도 하나의 장애물의 끝에 있는 및 다른 장애물까지 그 안에 있습니다.  각 장애물에 팀의 다른 멤버가 도착 하는 마지막 스레드가 기다려야 합니다.  모든 스레드를 동시에 대 한 장애물에 도착할 수 있도록이 대기 시간을 최소화 하기 위해 공유 작업 배포 해야 합니다.  일부를 공유 하는 경우 작업 시간에 포함 된  **에 대 한** 구문에서 `schedule` 절이이 목적을 위해 사용 될 수 있습니다.  
  
 있는 경우 동일한 개체에 대 한 일정의 선택에 대 한 참조가 반복 되는  **에 대 한** 메모리 시스템의 현재 상태와 크기를 캐시 및 메모리 액세스 시간이 일정, 고르지 않은 여부 등의 특성은 기본적으로 구문을 확인할 수 있습니다.  이러한 사항을 권장 일부 스레드가 상대적으로 적은 일부는 루프에서 작업에 할당 된 경우에 일관 되 게 동일한 집합을 일련의 루프, 배열의 요소를 참조 하는 각 스레드를 만들 수 있습니다.  이 사용 하 여 수행할 수 있습니다의  **정적** 일정과 같은 범위의 모든 루프를 사용 합니다.  참고 다음 예제에서는 0이 사용 됩니다 두 번째 루프에서 하한값으로도  **k** 일정 해야 한다면 자연스럽 게 될 수 있습니다.  
  
```  
#pragma omp parallel  
{  
#pragma omp for schedule(static)  
  for(i=0; i<n; i++)  
    a[i] = work1(i);  
#pragma omp for schedule(static)  
  for(i=0; i<n; i++)  
    if(i>=k) a[i] += work2(i);  
}  
```  
  
 나머지 예제 메모리 간주 액세스 수 없습니다 주요 고려와 별도로 지정 하지 않으면 모든 스레드가 비슷한 컴퓨터 리소스를 받을 합니다.  선택에 대 한 일정은 이러한 경우에는  **에 대 한** 구문의 가장 가까운 앞의 사이 수행 되는 모든 공유 작업에 따라 달라 집니다 묵시적된 닫는 장벽 및 장벽 또는 경우 다음 장애물에 가장 가까운는 `nowait` 절.  각 종류의 일정에 대 한 일정 종류 가장 좋은 선택이 될 것입니다 어떻게 간단한 예제를 보여 줍니다.  간략하게 설명 각 예제는 다음과 같습니다.  
  
 **정적** 일정입니다 또한 병렬 영역 하나만 포함 된 간단한 경우에 대 한 적절 한  **에 대 한** 구성에 필요한 작업 시간을 동일 하 게 반복 작업입니다.  
  
```  
#pragma omp parallel for schedule(static)  
for(i=0; i<n; i++) {  
  invariant_amount_of_work(i);  
}  
```  
  
 해당  **정적** 일정입니다 속성에 의해 대략 같은 수의 반복 다른 스레드와 각 스레드에 가져오는 및 특징에 할당 하는 반복 각 스레드에서 독립적으로 결정할 수 있습니다.  따라서 동기화 작업 시간을 배분 하는 데 필요한 및 각 반복 작업을 동일 하 게 필요 하다는 가정에서 모든 스레드를 같은 시간에 완료 해야 합니다.  
  
 팀의 `p` 스레드를,  *ceiling\(n\/p\)* 정수 수  *q*, 만족 하는  *n p \= \* q\-r* 와  *0 \< \= r \< p*.  구현 하는 하나는  **정적** 이은 지정 하는 대 한 예약  *q* 반복 하는 첫 번째  *p – 1에서* 는  스레드를 및  *q r* 마지막 스레드를 반복 합니다.  다른 적절 한 구현을 지정 하는  *q* 반복 하는 첫 번째  *p r* 스레드를 및  *q\-1* 의 나머지에 반복  *r* 스레드.  프로그램의 특정 구현 세부 정보에 의존해 서는 안 되는 이유이 보여 줍니다.  
  
 **동적** 일정의 경우에 해당 되는  **에 대 한** 다양 한, 나도 예측할 수 없는 많은 작업을 요구 반복으로 구성.  
  
```  
#pragma omp parallel for schedule(dynamic)  
  for(i=0; i<n; i++) {  
    unpredictable_amount_of_work(i);  
}  
```  
  
 해당  **동적** 일정의 최종 반복을 실행 하는 다른 스레드가 보다 오래 걸리는 대 한 장벽에 스레드를 대기 하는 속성에 의해 특징입니다.  이 각 할당에 대 한 동기화가 사용 가능 해지면 반복 한 번에 스레드를 할당 되도록 해야 합니다.  최소 청크 크기를 지정 하 여 동기화 하는 오버 헤드를 줄일 수 있습니다  *k* 스레드 할당 되도록 1 보다 큰  *k* 미만 한 번에  *k* 상태를 유지 합니다.  이렇게 다른 스레드의 최대의 마지막 청크를 실행 하는 것 보다 더 긴 장벽에 대기 스레드  *k* 반복 합니다.  
  
 해당  **동적** 일정 유용할 수 스레드 전산 자원을 다양 하 게 나타날 경우는 훨씬 다양 한 크기의 각 반복에 대 한 작업으로 같은 효과 가집니다.  마찬가지로, 동적 일정에서 스레드를 표시 하는 경우에 유용할 수도 있습니다의  **에 대 한** 다양 한 시점에서의이 경우 처럼 일부 구성의  **안내** 일정이 좋습니다 수 있습니다.  
  
 **안내** 일정에서 스레드 수 있습니다 도착 시 다양 한 시간에 하는 경우에 대 한 적절 한입니다는  **에 대 한** 각 반복 작업 같은 시간에 대 한 요청을 생성 합니다.  이 경우 발생할 수 있습니다, 예를 들어,는  **에 대 한** 구문 섹션에서 앞에 나  **에 대 한** 으로 구성 `nowait` 절.  
  
```  
#pragma omp parallel  
{  
  #pragma omp sections nowait  
  {  
    // ...  
  }  
  #pragma omp for schedule(guided)  
  for(i=0; i<n; i++) {  
    invariant_amount_of_work(i);  
  }  
}  
```  
  
 다음과 같이  **동적**의  **안내** 예약의 최종 반복을 실행 하는 다른 스레드가 것 보다 더 오래 또는 최종 관문에 스레드를 대기 하는 보장  *k* 청크 크기를 경우 반복  *k* 지정 됩니다.  이러한 일정 중에서  **기반** 일정입니다 묘사 속성에서 최소 동기화가 필요 하다는.  청크 크기에 대 한  *k*, 일반적인 구현을 지정 합니다  *q ceiling\(n\/p\) \=* 반복에서 첫 번째 사용 가능한 스레드 수를 설정  *n* 더 큰의  *n\-q* 및  *p \* k*, 모든 반복에 할당 된 때까지 반복 합니다.  
  
 최적 일정 선택 이러한 예제를 그대로 일반 경우는  **런타임** 일정이 다른 일정 한 청크 크기를 수정 하 고 프로그램을 다시 컴파일할 필요 없이 실험을 편리 하 게 되었습니다.  최적 일정 \(다양 한 예측 가능한 방식으로\) 프로그램에 적용 되는 입력된 데이터에 의존 때 것도 유용할 수 있습니다.  
  
 여러 일정 간의 장단점의 예를 보려면 1000 회 반복 8 스레드 간에 공유 하는 것이 좋습니다.  고정 값의 각 반복에서 작업 한다고 가정 하 고 시간 단위로 사용 하는.  
  
 모든 스레드를 동시에 시작할 경우 해당  **정적** 일정 동기화와 125 장치를 실행 하는 구문이 발생 합니다.  하지만 하나의 스레드가 늦게 도착에 100 단위 이라고 가정 합니다.  100 단위는 장애물에 나머지 7 개의 스레드를 기다리는 225를 전체 구문에 대 한 실행 시간을 증가 합니다.  
  
 때문에 모두의  **동적** 및  **안내** 일정 확인 장애물에 두 개 이상의 장치에 대 한 스레드 대기, 지연 된 스레드가 해당 동기화에서 지연이 있을 수도 증가 138 단위로 늘릴 수 있는 구문에 대 한 실행 시간이 발생 합니다.  이러한 지연을 미미할 경우 동기화 수가 1000에는 것이 중요 될  **동적** 있지만 대 한 유일한 41  **기반**, 하나의 기본 청크 크기를 가정 합니다.  청크 크기가 25,  **동적** 및  **기반** 모두 150 단위 및 모든 필요한 동기화가 유일한 40와 20, 어떤 지금 번호에서 연기를 각각 완료 합니다.